{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_shapes.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jullian-yapeter/CellularMaskRCNN/blob/master/train_shapes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "odrZDqx9giHG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Mask R-CNN - Train on Shapes Dataset\n",
        "\n",
        "\n",
        "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
        "\n",
        "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. "
      ]
    },
    {
      "metadata": {
        "id": "jtqMprV-gvk7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a2c2cae3-b649-4f28-eb9b-b483e2ccf32a"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gSjsYYSBg0_2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('drive/My Drive/Mask_RCNN')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XcWsjWVhg6BG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1516
        },
        "outputId": "f21c9cfe-17b6-4907-d67e-40a65c001146"
      },
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (4.0.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (0.29.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.13.1)\n",
            "Requirement already satisfied: tensorflow>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (1.13.0rc1)\n",
            "Requirement already satisfied: keras>=2.0.8 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (2.2.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (3.4.5.20)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (2.8.0)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (0.2.8)\n",
            "Requirement already satisfied: IPython[all] in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 12)) (5.5.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->-r requirements.txt (line 3)) (0.46)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.5.3)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 6)) (2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 6)) (1.0.1)\n",
            "Requirement already satisfied: six>=1.7.3 in /usr/local/lib/python3.6/dist-packages (from scikit-image->-r requirements.txt (line 6)) (1.11.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.33.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.6.1)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.13.0rc0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.0.9)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (1.0.7)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.8->-r requirements.txt (line 8)) (3.13)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug->-r requirements.txt (line 11)) (1.6.4.post2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug->-r requirements.txt (line 11)) (2.4.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.6.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.0.15)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (40.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (2.1.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.3.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.3.2)\n",
            "Requirement already satisfied: nbconvert; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.4.1)\n",
            "Requirement already satisfied: Sphinx>=1.3; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.8.4)\n",
            "Requirement already satisfied: qtconsole; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.4.3)\n",
            "Requirement already satisfied: requests; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (2.18.4)\n",
            "Requirement already satisfied: notebook; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (5.2.2)\n",
            "Requirement already satisfied: ipywidgets; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (7.4.2)\n",
            "Requirement already satisfied: testpath; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (0.4.2)\n",
            "Requirement already satisfied: ipyparallel; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (6.2.3)\n",
            "Requirement already satisfied: nose>=0.10.1; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (1.3.7)\n",
            "Requirement already satisfied: nbformat; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.4.0)\n",
            "Requirement already satisfied: ipykernel; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from IPython[all]->-r requirements.txt (line 12)) (4.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (3.0.1)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0rc0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (2.0.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->IPython[all]->-r requirements.txt (line 12)) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython[all]->-r requirements.txt (line 12)) (0.1.7)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->IPython[all]->-r requirements.txt (line 12)) (0.2.0)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.1.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.10)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.5.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.4.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (4.4.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.7.12)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.6.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.2.1)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.14)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (19.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.1.0)\n",
            "Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (5.2.4)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2018.11.29)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (4.5.3)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.8.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (3.4.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from ipyparallel; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (17.0.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2.6.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0rc0->tensorflow>=1.3.0->-r requirements.txt (line 7)) (5.1.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->nbconvert; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (1.1.0)\n",
            "Requirement already satisfied: pytz>=0a in /usr/local/lib/python3.6/dist-packages (from babel!=2.0,>=1.3->Sphinx>=1.3; extra == \"all\"->IPython[all]->-r requirements.txt (line 12)) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eMPHHj60g71w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "fdfef500-5b1c-4805-8c15-ecd5d87238ca"
      },
      "cell_type": "code",
      "source": [
        "!python3 setup.py install"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Fail load requirements file, so using default ones.\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing mask_rcnn.egg-info/PKG-INFO\n",
            "writing dependency_links to mask_rcnn.egg-info/dependency_links.txt\n",
            "writing top-level names to mask_rcnn.egg-info/top_level.txt\n",
            "reading manifest template 'MANIFEST.in'\n",
            "writing manifest file 'mask_rcnn.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "copying mrcnn/Copy of __init__.py -> build/lib/mrcnn\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/__init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/config.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/utils.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/parallel_model.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/visualize.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "copying build/lib/mrcnn/Copy of __init__.py -> build/bdist.linux-x86_64/egg/mrcnn\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/model.py to model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/config.py to config.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/parallel_model.py to parallel_model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/visualize.py to visualize.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mrcnn/Copy of __init__.py to Copy of __init__.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying mask_rcnn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating 'dist/mask_rcnn-2.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing mask_rcnn-2.1-py3.6.egg\n",
            "Removing /usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg\n",
            "Copying mask_rcnn-2.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "mask-rcnn 2.1 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/mask_rcnn-2.1-py3.6.egg\n",
            "Processing dependencies for mask-rcnn==2.1\n",
            "Finished processing dependencies for mask-rcnn==2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mZfFTfLzgiHI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2527050f-f2b7-4233-b99e-bb4ca9df1b2f"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Root directory of the project\n",
        "#ROOT_DIR = os.path.abspath(\"../../\")\n",
        "ROOT_DIR = '.'\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "import mrcnn.model as modellib\n",
        "from mrcnn import visualize\n",
        "from mrcnn.model import log\n",
        "\n",
        "%matplotlib inline \n",
        "\n",
        "# Directory to save logs and trained model\n",
        "#MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "MODEL_DIR = ROOT_DIR+'/logs'\n",
        "\n",
        "# Local path to trained weights file\n",
        "#COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "COCO_MODEL_PATH = ROOT_DIR+'/mask_rcnn_coco.h5'\n",
        "\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "1PvT4rSrgiHM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Configurations"
      ]
    },
    {
      "metadata": {
        "id": "aAU71yeCgiHN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "outputId": "cfaa5780-0d91-4442-bbf5-894dad3e3f29"
      },
      "cell_type": "code",
      "source": [
        "class ShapesConfig(Config):\n",
        "    \"\"\"Configuration for training on the toy shapes dataset.\n",
        "    Derives from the base Config class and overrides values specific\n",
        "    to the toy shapes dataset.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"shapes\"\n",
        "\n",
        "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
        "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 8\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
        "\n",
        "    # Use small images for faster training. Set the limits of the small side\n",
        "    # the large side, and that determines the image shape.\n",
        "    IMAGE_MIN_DIM = 128\n",
        "    IMAGE_MAX_DIM = 128\n",
        "\n",
        "    # Use smaller anchors because our image and objects are small\n",
        "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
        "\n",
        "    # Reduce training ROIs per image because the images are small and have\n",
        "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
        "    TRAIN_ROIS_PER_IMAGE = 32\n",
        "\n",
        "    # Use a small epoch since the data is simple\n",
        "    STEPS_PER_EPOCH = 100\n",
        "\n",
        "    # use small validation steps since the epoch is small\n",
        "    VALIDATION_STEPS = 5\n",
        "    \n",
        "config = ShapesConfig()\n",
        "config.display()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Configurations:\n",
            "BACKBONE                       resnet101\n",
            "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
            "BATCH_SIZE                     8\n",
            "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
            "COMPUTE_BACKBONE_SHAPE         None\n",
            "DETECTION_MAX_INSTANCES        100\n",
            "DETECTION_MIN_CONFIDENCE       0.7\n",
            "DETECTION_NMS_THRESHOLD        0.3\n",
            "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
            "GPU_COUNT                      1\n",
            "GRADIENT_CLIP_NORM             5.0\n",
            "IMAGES_PER_GPU                 8\n",
            "IMAGE_CHANNEL_COUNT            3\n",
            "IMAGE_MAX_DIM                  128\n",
            "IMAGE_META_SIZE                16\n",
            "IMAGE_MIN_DIM                  128\n",
            "IMAGE_MIN_SCALE                0\n",
            "IMAGE_RESIZE_MODE              square\n",
            "IMAGE_SHAPE                    [128 128   3]\n",
            "LEARNING_MOMENTUM              0.9\n",
            "LEARNING_RATE                  0.001\n",
            "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
            "MASK_POOL_SIZE                 14\n",
            "MASK_SHAPE                     [28, 28]\n",
            "MAX_GT_INSTANCES               100\n",
            "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
            "MINI_MASK_SHAPE                (56, 56)\n",
            "NAME                           shapes\n",
            "NUM_CLASSES                    4\n",
            "POOL_SIZE                      7\n",
            "POST_NMS_ROIS_INFERENCE        1000\n",
            "POST_NMS_ROIS_TRAINING         2000\n",
            "PRE_NMS_LIMIT                  6000\n",
            "ROI_POSITIVE_RATIO             0.33\n",
            "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
            "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
            "RPN_ANCHOR_STRIDE              1\n",
            "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
            "RPN_NMS_THRESHOLD              0.7\n",
            "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
            "STEPS_PER_EPOCH                100\n",
            "TOP_DOWN_PYRAMID_SIZE          256\n",
            "TRAIN_BN                       False\n",
            "TRAIN_ROIS_PER_IMAGE           32\n",
            "USE_MINI_MASK                  True\n",
            "USE_RPN_ROIS                   True\n",
            "VALIDATION_STEPS               5\n",
            "WEIGHT_DECAY                   0.0001\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6wE_Ls76giHQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Notebook Preferences"
      ]
    },
    {
      "metadata": {
        "id": "P-lZ0bQOgiHR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_ax(rows=1, cols=1, size=8):\n",
        "    \"\"\"Return a Matplotlib Axes array to be used in\n",
        "    all visualizations in the notebook. Provide a\n",
        "    central point to control graph sizes.\n",
        "    \n",
        "    Change the default size attribute to control the size\n",
        "    of rendered images\n",
        "    \"\"\"\n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q8GyWFJKgiHS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "Create a synthetic dataset\n",
        "\n",
        "Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:\n",
        "\n",
        "* load_image()\n",
        "* load_mask()\n",
        "* image_reference()"
      ]
    },
    {
      "metadata": {
        "id": "9DRc-MmlgiHT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ShapesDataset(utils.Dataset):\n",
        "    \"\"\"Generates the shapes synthetic dataset. The dataset consists of simple\n",
        "    shapes (triangles, squares, circles) placed randomly on a blank surface.\n",
        "    The images are generated on the fly. No file access required.\n",
        "    \"\"\"\n",
        "\n",
        "    def load_shapes(self, count, height, width):\n",
        "        \"\"\"Generate the requested number of synthetic images.\n",
        "        count: number of images to generate.\n",
        "        height, width: the size of the generated images.\n",
        "        \"\"\"\n",
        "        # Add classes\n",
        "        self.add_class(\"shapes\", 1, \"square\")\n",
        "        self.add_class(\"shapes\", 2, \"circle\")\n",
        "        self.add_class(\"shapes\", 3, \"triangle\")\n",
        "\n",
        "        # Add images\n",
        "        # Generate random specifications of images (i.e. color and\n",
        "        # list of shapes sizes and locations). This is more compact than\n",
        "        # actual images. Images are generated on the fly in load_image().\n",
        "        for i in range(count):\n",
        "            bg_color, shapes = self.random_image(height, width)\n",
        "            self.add_image(\"shapes\", image_id=i, path=None,\n",
        "                           width=width, height=height,\n",
        "                           bg_color=bg_color, shapes=shapes)\n",
        "\n",
        "    def load_image(self, image_id):\n",
        "        \"\"\"Generate an image from the specs of the given image ID.\n",
        "        Typically this function loads the image from a file, but\n",
        "        in this case it generates the image on the fly from the\n",
        "        specs in image_info.\n",
        "        \"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        bg_color = np.array(info['bg_color']).reshape([1, 1, 3])\n",
        "        image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
        "        image = image * bg_color.astype(np.uint8)\n",
        "        for shape, color, dims in info['shapes']:\n",
        "            image = self.draw_shape(image, shape, dims, color)\n",
        "        return image\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the shapes data of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"shapes\":\n",
        "            return info[\"shapes\"]\n",
        "        else:\n",
        "            super(self.__class__).image_reference(self, image_id)\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
        "        \"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        shapes = info['shapes']\n",
        "        count = len(shapes)\n",
        "        mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
        "        for i, (shape, _, dims) in enumerate(info['shapes']):\n",
        "            mask[:, :, i:i+1] = self.draw_shape(mask[:, :, i:i+1].copy(),\n",
        "                                                shape, dims, 1)\n",
        "        # Handle occlusions\n",
        "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
        "        for i in range(count-2, -1, -1):\n",
        "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
        "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
        "        # Map class names to class IDs.\n",
        "        class_ids = np.array([self.class_names.index(s[0]) for s in shapes])\n",
        "        return mask.astype(np.bool), class_ids.astype(np.int32)\n",
        "\n",
        "    def draw_shape(self, image, shape, dims, color):\n",
        "        \"\"\"Draws a shape from the given specs.\"\"\"\n",
        "        # Get the center x, y and the size s\n",
        "        x, y, s = dims\n",
        "        if shape == 'square':\n",
        "            cv2.rectangle(image, (x-s, y-s), (x+s, y+s), color, -1)\n",
        "        elif shape == \"circle\":\n",
        "            cv2.circle(image, (x, y), s, color, -1)\n",
        "        elif shape == \"triangle\":\n",
        "            points = np.array([[(x, y-s),\n",
        "                                (x-s/math.sin(math.radians(60)), y+s),\n",
        "                                (x+s/math.sin(math.radians(60)), y+s),\n",
        "                                ]], dtype=np.int32)\n",
        "            cv2.fillPoly(image, points, color)\n",
        "        return image\n",
        "\n",
        "    def random_shape(self, height, width):\n",
        "        \"\"\"Generates specifications of a random shape that lies within\n",
        "        the given height and width boundaries.\n",
        "        Returns a tuple of three valus:\n",
        "        * The shape name (square, circle, ...)\n",
        "        * Shape color: a tuple of 3 values, RGB.\n",
        "        * Shape dimensions: A tuple of values that define the shape size\n",
        "                            and location. Differs per shape type.\n",
        "        \"\"\"\n",
        "        # Shape\n",
        "        shape = random.choice([\"square\", \"circle\", \"triangle\"])\n",
        "        # Color\n",
        "        color = tuple([random.randint(0, 255) for _ in range(3)])\n",
        "        # Center x, y\n",
        "        buffer = 20\n",
        "        y = random.randint(buffer, height - buffer - 1)\n",
        "        x = random.randint(buffer, width - buffer - 1)\n",
        "        # Size\n",
        "        s = random.randint(buffer, height//4)\n",
        "        return shape, color, (x, y, s)\n",
        "\n",
        "    def random_image(self, height, width):\n",
        "        \"\"\"Creates random specifications of an image with multiple shapes.\n",
        "        Returns the background color of the image and a list of shape\n",
        "        specifications that can be used to draw the image.\n",
        "        \"\"\"\n",
        "        # Pick random background color\n",
        "        bg_color = np.array([random.randint(0, 255) for _ in range(3)])\n",
        "        # Generate a few random shapes and record their\n",
        "        # bounding boxes\n",
        "        shapes = []\n",
        "        boxes = []\n",
        "        N = random.randint(1, 4)\n",
        "        for _ in range(N):\n",
        "            shape, color, dims = self.random_shape(height, width)\n",
        "            shapes.append((shape, color, dims))\n",
        "            x, y, s = dims\n",
        "            boxes.append([y-s, x-s, y+s, x+s])\n",
        "        # Apply non-max suppression wit 0.3 threshold to avoid\n",
        "        # shapes covering each other\n",
        "        keep_ixs = utils.non_max_suppression(np.array(boxes), np.arange(N), 0.3)\n",
        "        shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]\n",
        "        return bg_color, shapes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nHTeXMY9giHW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training dataset\n",
        "dataset_train = ShapesDataset()\n",
        "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
        "dataset_train.prepare()\n",
        "\n",
        "# Validation dataset\n",
        "dataset_val = ShapesDataset()\n",
        "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
        "dataset_val.prepare()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gAOHEI9XgiHX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "outputId": "79dbec8b-da4b-42fd-adc1-c3ff1344d952"
      },
      "cell_type": "code",
      "source": [
        "# Load and display random samples\n",
        "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
        "for image_id in image_ids:\n",
        "    image = dataset_train.load_image(image_id)\n",
        "    mask, class_ids = dataset_train.load_mask(image_id)\n",
        "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAygAAACnCAYAAAD6+nhhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1008x360 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAygAAACnCAYAAAD6+nhhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noIUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1008x360 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAygAAACnCAYAAAD6+nhhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1008x360 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAygAAACnCAYAAAD6+nhhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2hAoAABAGwIFAABoQ6AAAABt/B+tkts2cpoqywAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1008x360 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "BuUcbBEdgiHf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create Model"
      ]
    },
    {
      "metadata": {
        "id": "U0-Ag6cAgiHf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "0e5795e2-a4cf-4d2e-a2e6-28dbec808d3d"
      },
      "cell_type": "code",
      "source": [
        "# Create model in training mode\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                          model_dir=MODEL_DIR)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "ykUq2FldgiHh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Which weights to start with?\n",
        "init_with = \"coco\"  # imagenet, coco, or last\n",
        "\n",
        "if init_with == \"imagenet\":\n",
        "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
        "elif init_with == \"coco\":\n",
        "    # Load weights trained on MS COCO, but skip layers that\n",
        "    # are different due to the different number of classes\n",
        "    # See README for instructions to download the COCO weights\n",
        "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
        "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
        "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "elif init_with == \"last\":\n",
        "    # Load the last model you trained and continue training\n",
        "    model.load_weights(model.find_last(), by_name=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kBsps2HSgiHk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "Train in two stages:\n",
        "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
        "\n",
        "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "t0PJCU2IgiHl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "outputId": "1af09368-3bb5-4079-caf5-68529d525e9f"
      },
      "cell_type": "code",
      "source": [
        "# Train the head branches\n",
        "# Passing layers=\"heads\" freezes all layers except the head\n",
        "# layers. You can also pass a regular expression to select\n",
        "# which layers to train by name pattern.\n",
        "model.train(dataset_train, dataset_val, \n",
        "            learning_rate=config.LEARNING_RATE, \n",
        "            epochs=1, \n",
        "            layers='heads')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: ./logs/shapes20190220T1052/mask_rcnn_shapes_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "100/100 [==============================] - 117s 1s/step - loss: 1.6865 - rpn_class_loss: 0.0305 - rpn_bbox_loss: 0.6048 - mrcnn_class_loss: 0.3696 - mrcnn_bbox_loss: 0.4164 - mrcnn_mask_loss: 0.2652 - val_loss: 1.1508 - val_rpn_class_loss: 0.0179 - val_rpn_bbox_loss: 0.4629 - val_mrcnn_class_loss: 0.1891 - val_mrcnn_bbox_loss: 0.2420 - val_mrcnn_mask_loss: 0.2389\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "ieL1dvz4giHo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4236
        },
        "outputId": "3811ae62-50f2-42b6-f4f6-f7218125f65a"
      },
      "cell_type": "code",
      "source": [
        "# Fine tune all layers\n",
        "# Passing layers=\"all\" trains all layers. You can also \n",
        "# pass a regular expression to select which layers to\n",
        "# train by name pattern.\n",
        "model.train(dataset_train, dataset_val, \n",
        "            learning_rate=config.LEARNING_RATE / 10,\n",
        "            epochs=2, \n",
        "            layers=\"all\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Starting at epoch 1. LR=0.0001\n",
            "\n",
            "Checkpoint Path: ./logs/shapes20190220T1052/mask_rcnn_shapes_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "conv1                  (Conv2D)\n",
            "bn_conv1               (BatchNorm)\n",
            "res2a_branch2a         (Conv2D)\n",
            "bn2a_branch2a          (BatchNorm)\n",
            "res2a_branch2b         (Conv2D)\n",
            "bn2a_branch2b          (BatchNorm)\n",
            "res2a_branch2c         (Conv2D)\n",
            "res2a_branch1          (Conv2D)\n",
            "bn2a_branch2c          (BatchNorm)\n",
            "bn2a_branch1           (BatchNorm)\n",
            "res2b_branch2a         (Conv2D)\n",
            "bn2b_branch2a          (BatchNorm)\n",
            "res2b_branch2b         (Conv2D)\n",
            "bn2b_branch2b          (BatchNorm)\n",
            "res2b_branch2c         (Conv2D)\n",
            "bn2b_branch2c          (BatchNorm)\n",
            "res2c_branch2a         (Conv2D)\n",
            "bn2c_branch2a          (BatchNorm)\n",
            "res2c_branch2b         (Conv2D)\n",
            "bn2c_branch2b          (BatchNorm)\n",
            "res2c_branch2c         (Conv2D)\n",
            "bn2c_branch2c          (BatchNorm)\n",
            "res3a_branch2a         (Conv2D)\n",
            "bn3a_branch2a          (BatchNorm)\n",
            "res3a_branch2b         (Conv2D)\n",
            "bn3a_branch2b          (BatchNorm)\n",
            "res3a_branch2c         (Conv2D)\n",
            "res3a_branch1          (Conv2D)\n",
            "bn3a_branch2c          (BatchNorm)\n",
            "bn3a_branch1           (BatchNorm)\n",
            "res3b_branch2a         (Conv2D)\n",
            "bn3b_branch2a          (BatchNorm)\n",
            "res3b_branch2b         (Conv2D)\n",
            "bn3b_branch2b          (BatchNorm)\n",
            "res3b_branch2c         (Conv2D)\n",
            "bn3b_branch2c          (BatchNorm)\n",
            "res3c_branch2a         (Conv2D)\n",
            "bn3c_branch2a          (BatchNorm)\n",
            "res3c_branch2b         (Conv2D)\n",
            "bn3c_branch2b          (BatchNorm)\n",
            "res3c_branch2c         (Conv2D)\n",
            "bn3c_branch2c          (BatchNorm)\n",
            "res3d_branch2a         (Conv2D)\n",
            "bn3d_branch2a          (BatchNorm)\n",
            "res3d_branch2b         (Conv2D)\n",
            "bn3d_branch2b          (BatchNorm)\n",
            "res3d_branch2c         (Conv2D)\n",
            "bn3d_branch2c          (BatchNorm)\n",
            "res4a_branch2a         (Conv2D)\n",
            "bn4a_branch2a          (BatchNorm)\n",
            "res4a_branch2b         (Conv2D)\n",
            "bn4a_branch2b          (BatchNorm)\n",
            "res4a_branch2c         (Conv2D)\n",
            "res4a_branch1          (Conv2D)\n",
            "bn4a_branch2c          (BatchNorm)\n",
            "bn4a_branch1           (BatchNorm)\n",
            "res4b_branch2a         (Conv2D)\n",
            "bn4b_branch2a          (BatchNorm)\n",
            "res4b_branch2b         (Conv2D)\n",
            "bn4b_branch2b          (BatchNorm)\n",
            "res4b_branch2c         (Conv2D)\n",
            "bn4b_branch2c          (BatchNorm)\n",
            "res4c_branch2a         (Conv2D)\n",
            "bn4c_branch2a          (BatchNorm)\n",
            "res4c_branch2b         (Conv2D)\n",
            "bn4c_branch2b          (BatchNorm)\n",
            "res4c_branch2c         (Conv2D)\n",
            "bn4c_branch2c          (BatchNorm)\n",
            "res4d_branch2a         (Conv2D)\n",
            "bn4d_branch2a          (BatchNorm)\n",
            "res4d_branch2b         (Conv2D)\n",
            "bn4d_branch2b          (BatchNorm)\n",
            "res4d_branch2c         (Conv2D)\n",
            "bn4d_branch2c          (BatchNorm)\n",
            "res4e_branch2a         (Conv2D)\n",
            "bn4e_branch2a          (BatchNorm)\n",
            "res4e_branch2b         (Conv2D)\n",
            "bn4e_branch2b          (BatchNorm)\n",
            "res4e_branch2c         (Conv2D)\n",
            "bn4e_branch2c          (BatchNorm)\n",
            "res4f_branch2a         (Conv2D)\n",
            "bn4f_branch2a          (BatchNorm)\n",
            "res4f_branch2b         (Conv2D)\n",
            "bn4f_branch2b          (BatchNorm)\n",
            "res4f_branch2c         (Conv2D)\n",
            "bn4f_branch2c          (BatchNorm)\n",
            "res4g_branch2a         (Conv2D)\n",
            "bn4g_branch2a          (BatchNorm)\n",
            "res4g_branch2b         (Conv2D)\n",
            "bn4g_branch2b          (BatchNorm)\n",
            "res4g_branch2c         (Conv2D)\n",
            "bn4g_branch2c          (BatchNorm)\n",
            "res4h_branch2a         (Conv2D)\n",
            "bn4h_branch2a          (BatchNorm)\n",
            "res4h_branch2b         (Conv2D)\n",
            "bn4h_branch2b          (BatchNorm)\n",
            "res4h_branch2c         (Conv2D)\n",
            "bn4h_branch2c          (BatchNorm)\n",
            "res4i_branch2a         (Conv2D)\n",
            "bn4i_branch2a          (BatchNorm)\n",
            "res4i_branch2b         (Conv2D)\n",
            "bn4i_branch2b          (BatchNorm)\n",
            "res4i_branch2c         (Conv2D)\n",
            "bn4i_branch2c          (BatchNorm)\n",
            "res4j_branch2a         (Conv2D)\n",
            "bn4j_branch2a          (BatchNorm)\n",
            "res4j_branch2b         (Conv2D)\n",
            "bn4j_branch2b          (BatchNorm)\n",
            "res4j_branch2c         (Conv2D)\n",
            "bn4j_branch2c          (BatchNorm)\n",
            "res4k_branch2a         (Conv2D)\n",
            "bn4k_branch2a          (BatchNorm)\n",
            "res4k_branch2b         (Conv2D)\n",
            "bn4k_branch2b          (BatchNorm)\n",
            "res4k_branch2c         (Conv2D)\n",
            "bn4k_branch2c          (BatchNorm)\n",
            "res4l_branch2a         (Conv2D)\n",
            "bn4l_branch2a          (BatchNorm)\n",
            "res4l_branch2b         (Conv2D)\n",
            "bn4l_branch2b          (BatchNorm)\n",
            "res4l_branch2c         (Conv2D)\n",
            "bn4l_branch2c          (BatchNorm)\n",
            "res4m_branch2a         (Conv2D)\n",
            "bn4m_branch2a          (BatchNorm)\n",
            "res4m_branch2b         (Conv2D)\n",
            "bn4m_branch2b          (BatchNorm)\n",
            "res4m_branch2c         (Conv2D)\n",
            "bn4m_branch2c          (BatchNorm)\n",
            "res4n_branch2a         (Conv2D)\n",
            "bn4n_branch2a          (BatchNorm)\n",
            "res4n_branch2b         (Conv2D)\n",
            "bn4n_branch2b          (BatchNorm)\n",
            "res4n_branch2c         (Conv2D)\n",
            "bn4n_branch2c          (BatchNorm)\n",
            "res4o_branch2a         (Conv2D)\n",
            "bn4o_branch2a          (BatchNorm)\n",
            "res4o_branch2b         (Conv2D)\n",
            "bn4o_branch2b          (BatchNorm)\n",
            "res4o_branch2c         (Conv2D)\n",
            "bn4o_branch2c          (BatchNorm)\n",
            "res4p_branch2a         (Conv2D)\n",
            "bn4p_branch2a          (BatchNorm)\n",
            "res4p_branch2b         (Conv2D)\n",
            "bn4p_branch2b          (BatchNorm)\n",
            "res4p_branch2c         (Conv2D)\n",
            "bn4p_branch2c          (BatchNorm)\n",
            "res4q_branch2a         (Conv2D)\n",
            "bn4q_branch2a          (BatchNorm)\n",
            "res4q_branch2b         (Conv2D)\n",
            "bn4q_branch2b          (BatchNorm)\n",
            "res4q_branch2c         (Conv2D)\n",
            "bn4q_branch2c          (BatchNorm)\n",
            "res4r_branch2a         (Conv2D)\n",
            "bn4r_branch2a          (BatchNorm)\n",
            "res4r_branch2b         (Conv2D)\n",
            "bn4r_branch2b          (BatchNorm)\n",
            "res4r_branch2c         (Conv2D)\n",
            "bn4r_branch2c          (BatchNorm)\n",
            "res4s_branch2a         (Conv2D)\n",
            "bn4s_branch2a          (BatchNorm)\n",
            "res4s_branch2b         (Conv2D)\n",
            "bn4s_branch2b          (BatchNorm)\n",
            "res4s_branch2c         (Conv2D)\n",
            "bn4s_branch2c          (BatchNorm)\n",
            "res4t_branch2a         (Conv2D)\n",
            "bn4t_branch2a          (BatchNorm)\n",
            "res4t_branch2b         (Conv2D)\n",
            "bn4t_branch2b          (BatchNorm)\n",
            "res4t_branch2c         (Conv2D)\n",
            "bn4t_branch2c          (BatchNorm)\n",
            "res4u_branch2a         (Conv2D)\n",
            "bn4u_branch2a          (BatchNorm)\n",
            "res4u_branch2b         (Conv2D)\n",
            "bn4u_branch2b          (BatchNorm)\n",
            "res4u_branch2c         (Conv2D)\n",
            "bn4u_branch2c          (BatchNorm)\n",
            "res4v_branch2a         (Conv2D)\n",
            "bn4v_branch2a          (BatchNorm)\n",
            "res4v_branch2b         (Conv2D)\n",
            "bn4v_branch2b          (BatchNorm)\n",
            "res4v_branch2c         (Conv2D)\n",
            "bn4v_branch2c          (BatchNorm)\n",
            "res4w_branch2a         (Conv2D)\n",
            "bn4w_branch2a          (BatchNorm)\n",
            "res4w_branch2b         (Conv2D)\n",
            "bn4w_branch2b          (BatchNorm)\n",
            "res4w_branch2c         (Conv2D)\n",
            "bn4w_branch2c          (BatchNorm)\n",
            "res5a_branch2a         (Conv2D)\n",
            "bn5a_branch2a          (BatchNorm)\n",
            "res5a_branch2b         (Conv2D)\n",
            "bn5a_branch2b          (BatchNorm)\n",
            "res5a_branch2c         (Conv2D)\n",
            "res5a_branch1          (Conv2D)\n",
            "bn5a_branch2c          (BatchNorm)\n",
            "bn5a_branch1           (BatchNorm)\n",
            "res5b_branch2a         (Conv2D)\n",
            "bn5b_branch2a          (BatchNorm)\n",
            "res5b_branch2b         (Conv2D)\n",
            "bn5b_branch2b          (BatchNorm)\n",
            "res5b_branch2c         (Conv2D)\n",
            "bn5b_branch2c          (BatchNorm)\n",
            "res5c_branch2a         (Conv2D)\n",
            "bn5c_branch2a          (BatchNorm)\n",
            "res5c_branch2b         (Conv2D)\n",
            "bn5c_branch2b          (BatchNorm)\n",
            "res5c_branch2c         (Conv2D)\n",
            "bn5c_branch2c          (BatchNorm)\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/2\n",
            "100/100 [==============================] - 168s 2s/step - loss: 0.8351 - rpn_class_loss: 0.0164 - rpn_bbox_loss: 0.4143 - mrcnn_class_loss: 0.1219 - mrcnn_bbox_loss: 0.1487 - mrcnn_mask_loss: 0.1337 - val_loss: 0.8891 - val_rpn_class_loss: 0.0184 - val_rpn_bbox_loss: 0.4407 - val_mrcnn_class_loss: 0.1293 - val_mrcnn_bbox_loss: 0.1430 - val_mrcnn_mask_loss: 0.1577\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ALynzxAAgiHr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save weights\n",
        "# Typically not needed because callbacks save after every epoch\n",
        "# Uncomment to save manually\n",
        "# model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
        "# model.keras_model.save_weights(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mJedMkFvgiHt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Detection"
      ]
    },
    {
      "metadata": {
        "id": "Wa485f6igiHt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "302bd904-bd24-4292-8d55-ec9779c338e6"
      },
      "cell_type": "code",
      "source": [
        "class InferenceConfig(ShapesConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "inference_config = InferenceConfig()\n",
        "\n",
        "# Recreate the model in inference mode\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \n",
        "                          config=inference_config,\n",
        "                          model_dir=MODEL_DIR)\n",
        "\n",
        "# Get path to saved weights\n",
        "# Either set a specific path or find last trained weights\n",
        "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
        "model_path = model.find_last()\n",
        "\n",
        "# Load trained weights\n",
        "print(\"Loading weights from \", model_path)\n",
        "model.load_weights(model_path, by_name=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/drive/My Drive/Mask_RCNN/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Loading weights from  ./logs/shapes20190220T1052/mask_rcnn_shapes_0002.h5\n",
            "Re-starting from epoch 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "00t_esnzgiHw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "194ad0e9-b5a9-49cd-e53c-5ed1423965bd"
      },
      "cell_type": "code",
      "source": [
        "# Test on a random image\n",
        "image_id = random.choice(dataset_val.image_ids)\n",
        "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "    modellib.load_image_gt(dataset_val, inference_config, \n",
        "                           image_id, use_mini_mask=False)\n",
        "\n",
        "log(\"original_image\", original_image)\n",
        "log(\"image_meta\", image_meta)\n",
        "log(\"gt_class_id\", gt_class_id)\n",
        "log(\"gt_bbox\", gt_bbox)\n",
        "log(\"gt_mask\", gt_mask)\n",
        "\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original_image           shape: (128, 128, 3)         min:   57.00000  max:  243.00000  uint8\n",
            "image_meta               shape: (16,)                 min:    0.00000  max:  128.00000  int64\n",
            "gt_class_id              shape: (2,)                  min:    1.00000  max:    1.00000  int32\n",
            "gt_bbox                  shape: (2, 4)                min:   29.00000  max:  128.00000  int32\n",
            "gt_mask                  shape: (128, 128, 2)         min:    0.00000  max:    1.00000  bool\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdkAAAHSCAYAAACggLHBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/x14MGEzh5XxAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "S9pvRCqCgiH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "60e2d70e-0a68-43b1-ed02-ee60d4154d0f"
      },
      "cell_type": "code",
      "source": [
        "results = model.detect([original_image], verbose=1)\n",
        "\n",
        "r = results[0]\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
        "                            dataset_val.class_names, r['scores'], ax=get_ax())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing 1 images\n",
            "image                    shape: (128, 128, 3)         min:   57.00000  max:  243.00000  uint8\n",
            "molded_images            shape: (1, 128, 128, 3)      min:  -59.80000  max:  139.10000  float64\n",
            "image_metas              shape: (1, 16)               min:    0.00000  max:  128.00000  int64\n",
            "anchors                  shape: (1, 4092, 4)          min:   -0.71267  max:    1.20874  float32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdkAAAHSCAYAAACggLHBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9dg6OjxugiH4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ]
    },
    {
      "metadata": {
        "id": "ECiSRp6ogiH7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f092803f-1083-4e0f-a147-ce1ddc4a86c4"
      },
      "cell_type": "code",
      "source": [
        "# Compute VOC-Style mAP @ IoU=0.5\n",
        "# Running on 10 images. Increase for better accuracy.\n",
        "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
        "APs = []\n",
        "for image_id in image_ids:\n",
        "    # Load image and ground truth data\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
        "        modellib.load_image_gt(dataset_val, inference_config,\n",
        "                               image_id, use_mini_mask=False)\n",
        "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
        "    # Run object detection\n",
        "    results = model.detect([image], verbose=0)\n",
        "    r = results[0]\n",
        "    # Compute AP\n",
        "    AP, precisions, recalls, overlaps =\\\n",
        "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
        "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
        "    APs.append(AP)\n",
        "    \n",
        "print(\"mAP: \", np.mean(APs))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mAP:  0.8000000059604645\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9NsGbo_RgiH-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}